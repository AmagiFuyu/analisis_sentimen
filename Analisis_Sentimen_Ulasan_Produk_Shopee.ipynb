{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxPgFEhztHOw"
      },
      "source": [
        "## Download Library Sastrawi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-dK-hzutNUH",
        "outputId": "718e9157-7012-4e40-c6a2-27238534051f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfvuSLbtq6I4"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpyffUW4qw6T",
        "outputId": "07f55725-9884-4a81-a73b-080cc8995010"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import Library\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import nltk\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "\n",
        "#Download NLTK Stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAJrCYRCbIRx"
      },
      "source": [
        "## Scraping Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnIeZtpMbKRh"
      },
      "outputs": [],
      "source": [
        "def scrape_playstore_reviews(app_id, num_reviews=3000):\n",
        "    reviews = []\n",
        "    for page in range(1, num_reviews // 40 + 2):\n",
        "        url = f\"https://play.google.com/store/getreviews?authuser=0&reviewType=0&pageNum={page}&id={app_id}&reviewSortOrder=0&xhr=1\"\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0',\n",
        "            'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8'\n",
        "        }\n",
        "        data = f'reviewType=0&pageNum={page}&id={app_id}&reviewSortOrder=0&xhr=1'\n",
        "        response = requests.post(url, headers=headers, data=data)\n",
        "        try:\n",
        "            content = json.loads(response.text[6:])[0][2]\n",
        "            soup = BeautifulSoup(content, 'html.parser')\n",
        "            for div in soup.find_all('div', class_='review-body'):\n",
        "                text = div.text.strip()\n",
        "                if text:\n",
        "                    reviews.append(text)\n",
        "        except Exception:\n",
        "            continue\n",
        "        time.sleep(0.5)\n",
        "        if len(reviews) >= num_reviews:\n",
        "            break\n",
        "    return pd.DataFrame(reviews[:num_reviews], columns=['review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvM5rgCVZa2i"
      },
      "source": [
        "## Preprocessing Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r0O34ikZjpa"
      },
      "outputs": [],
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "    tokens = text.split()\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fgn-AoKZ5DR"
      },
      "source": [
        "## Ekstraksi Fitur & Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxEfroAzZ-Ia",
        "outputId": "61494a8d-a7ee-442c-a2bd-98eaf138bcaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Jumlah total data: 3250\n",
            "\n",
            "Distribusi label:\n",
            "label\n",
            "positif    2000\n",
            "netral     1000\n",
            "negatif     250\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "app_id = \"com.shopee.id\"\n",
        "df = scrape_playstore_reviews(app_id, num_reviews=3000)\n",
        "\n",
        "# Tambahkan data kompleks manual\n",
        "additional_reviews = [\n",
        "    \"Aplikasi ini sangat membantu, tapi kadang lemot kalau sinyal buruk. Overall oke lah.\",\n",
        "    \"Belanja pertama lancar, yang kedua barangnya lama banget dikirim. Kecewa sih.\",\n",
        "    \"UI/UX sudah membaik dari versi sebelumnya, tapi sistem pencarian masih tidak akurat.\",\n",
        "    \"Kenapa tiba-tiba aplikasi force close terus? Padahal sebelumnya lancar.\",\n",
        "    \"Pengalaman belanja sangat menyenangkan, pengiriman cepat, CS responsif. Good job!\",\n",
        "    \"Lumayan sih, kadang ada bug tapi sering update juga.\",\n",
        "    \"Saya sudah dua kali beli di sini dan selalu memuaskan. Penjual responsif, pengiriman cepat.\",\n",
        "    \"Setelah update terbaru, aplikasi sering ngelag. Harap segera diperbaiki.\",\n",
        "    \"Barangnya tidak sesuai deskripsi, sangat mengecewakan dan CS tidak membantu.\",\n",
        "    \"Fitur promo sering error saat checkout, padahal sinyal bagus dan aplikasi sudah diupdate.\",\n",
        "    \"Packing rapi, barang aman sampai tujuan. Terima kasih Shopee!\",\n",
        "    \"Cukup puas, hanya saja notifikasi suka telat muncul. Mohon ditingkatkan.\",\n",
        "    \"Awalnya lancar, tapi sekarang sering keluar sendiri dari aplikasi.\"\n",
        "]\n",
        "df_complex = pd.DataFrame(additional_reviews * 250, columns=['review'])  # Tambah kompleks hingga 3250 data\n",
        "df = pd.concat([df, df_complex], ignore_index=True)\n",
        "\n",
        "positive_keywords = [\"bagus\", \"mantap\", \"cepat\", \"puas\", \"keren\", \"terbaik\", \"menyenangkan\", \"lancar\", \"responsif\", \"oke\"]\n",
        "negative_keywords = [\"jelek\", \"lemot\", \"buruk\", \"error\", \"gagal\", \"parah\", \"kecewa\", \"bug\", \"force close\"]\n",
        "\n",
        "def label_sentiment(text):\n",
        "    text = text.lower()\n",
        "    if any(word in text for word in positive_keywords):\n",
        "        return \"positif\"\n",
        "    elif any(word in text for word in negative_keywords):\n",
        "        return \"negatif\"\n",
        "    else:\n",
        "        return \"netral\"\n",
        "\n",
        "df[\"label\"] = df[\"review\"].apply(label_sentiment)\n",
        "df = df[df['label'].isin(['positif', 'netral', 'negatif'])]\n",
        "df[\"clean_review\"] = df[\"review\"].apply(preprocess_text)\n",
        "\n",
        "# Cek jumlah data\n",
        "print(\"\\nJumlah total data:\", len(df))\n",
        "print(\"\\nDistribusi label:\")\n",
        "print(df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRsM7L1YaTxC"
      },
      "source": [
        "## Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoJ6oeZgaYOa"
      },
      "outputs": [],
      "source": [
        "X = df[\"clean_review\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP0pl65KafF6"
      },
      "source": [
        "## Model Traning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPgUhy6WahgJ"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj6LA_SNvVvv"
      },
      "source": [
        "### Model 1: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUj68flfvjIn"
      },
      "outputs": [],
      "source": [
        "# Logisitic Regression\n",
        "lr = LogisticRegression(max_iter=300)\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVb0Yu-DvaPf"
      },
      "source": [
        "### Model 2: SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAtG3T3JvtA3"
      },
      "outputs": [],
      "source": [
        "# SVM\n",
        "svm = SVC()\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wel72_t2vdc_"
      },
      "source": [
        "### Model 3: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n9fzpwdvuGn"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_tfidf, y_train)\n",
        "y_pred_rf = rf.predict(X_test_tfidf)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSeYwKWEv_DH"
      },
      "source": [
        "## Evaluasi Tiap Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWGKou9kv8BA",
        "outputId": "c774bc99-9891-4862-9ee2-deb3d38ae89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Akurasi Logistic Regression: 100.00%\n",
            "\n",
            "Akurasi SVM: 100.00%\n",
            "\n",
            "Akurasi Random Forest: 100.00%\n",
            "\n",
            "Classification Report - Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       1.00      1.00      1.00        59\n",
            "      netral       1.00      1.00      1.00       213\n",
            "     positif       1.00      1.00      1.00       378\n",
            "\n",
            "    accuracy                           1.00       650\n",
            "   macro avg       1.00      1.00      1.00       650\n",
            "weighted avg       1.00      1.00      1.00       650\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nAkurasi Logistic Regression: {:.2f}%\".format(acc_lr))\n",
        "print(\"\\nAkurasi SVM: {:.2f}%\".format(acc_svm))\n",
        "print(\"\\nAkurasi Random Forest: {:.2f}%\".format(acc_rf))\n",
        "\n",
        "print(\"\\nClassification Report - Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1OR_eZ22N7n"
      },
      "source": [
        "## Simpan dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB6GCiEC2Qy-",
        "outputId": "6619fd81-2b4d-42f1-b3c0-8ba4ff12d8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset berhasil disimpan ke 'dataset_ulasan_shopee.csv'\n"
          ]
        }
      ],
      "source": [
        "# Simpan dataset ke file CSV\n",
        "df.to_csv(\"dataset_ulasan_shopee.csv\", index=False)\n",
        "print(\"Dataset berhasil disimpan ke 'dataset_ulasan_shopee.csv'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
